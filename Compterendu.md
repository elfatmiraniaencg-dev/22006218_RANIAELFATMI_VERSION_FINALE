
<p align="left">
  <img src="logoencgsettat.jpg" width="100" alt="Logo">
</p>

# üìò GUIDE COMPLET : PROJET DATA SCIENCE - MARKETING BANCAIRE

<p align="center">
  <img src="image%20rania.jpg" width="350">
</p>


R√©alis√© par : RANIA EL FATMI 

Groupe : 2 FIN

---

## 1Ô∏è‚É£ Le Contexte M√©tier et la Mission

### üéØ Le Probl√®me (Business Case)

Une banque lance des campagnes de t√©l√©marketing pour proposer un **d√©p√¥t √† terme** (Term Deposit).

**Probl√®mes actuels :**
- La plupart des clients refusent
- Appeler tout le monde co√ªte cher
- Les campagnes longues fatiguent les conseillers
- Taux de conversion faible : **‚âà 11%**

### üéØ Objectif Business

Cr√©er un mod√®le ML qui pr√©dit si un client va souscrire au produit.

**Enjeux strat√©giques :**
- ‚úÖ R√©duire les appels inutiles
- ‚úÖ Cibler les clients √† haute probabilit√©
- ‚úÖ Augmenter le taux de conversion
- ‚úÖ Diminuer le co√ªt par conversion

### ‚ö†Ô∏è Co√ªt Asym√©trique des Erreurs

| Type d'Erreur | Impact Business |
|---------------|-----------------|
| **Faux Positif** (pr√©dit "yes" ‚Üí client dit "no") | Co√ªt : appel inutile |
| **Faux N√©gatif** (pr√©dit "no" ‚Üí client dit "yes") | **CRITIQUE** : opportunit√© perdue |

**‚û°Ô∏è M√©trique prioritaire : RECALL sur la classe "yes"**

---

## 2Ô∏è‚É£ Structure du Code Python

```python
# 1. Chargement des donn√©es
df = pd.concat([X, y], axis=1)

# 2. Preprocessing Pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# 3. Mod√®le complet
model = Pipeline(steps=[
    ('preprocessing', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

# 4. Entra√Ænement et pr√©diction
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
```

---

## 3Ô∏è‚É£ Analyse des Donn√©es (Profil Marketing)

### üìÇ Le Dataset "Bank Marketing"

- **41 188** appels t√©l√©phoniques
- **20** variables explicatives
- **1** variable cible : `y` (yes / no)

### Types de Variables

| Type | Exemples | R√¥le |
|------|----------|------|
| **Num√©riques** | age, duration, euribor3m | Facteurs quantitatifs |
| **Cat√©gorielles** | job, marital, education | Profil socio-√©conomique |
| **Macro-√©conomie** | cons.conf.idx, emp.var.rate | Contexte financier |
| **Historique** | previous, poutcome | Campagnes pass√©es |

### üí° Insight Cl√© : Variable "duration"

‚ö†Ô∏è **DATA LEAKAGE** : La dur√©e de l'appel (`duration`) est tr√®s corr√©l√©e au r√©sultat, MAIS elle n'est connue qu'**apr√®s** l'appel.

**‚û°Ô∏è NE PAS l'utiliser en production !**

---

## 4Ô∏è‚É£ Analyse Exploratoire (EDA)

### üìä Distribution de la Cible

Le dataset est **d√©s√©quilibr√©** :
- **88%** : no
- **12%** : yes

**‚ö†Ô∏è Cons√©quence** : L'accuracy seule est trompeuse. Un mod√®le na√Øf qui pr√©dit toujours "no" aurait 88% d'accuracy !

### üìà Profilage des Variables

**1. Variables socio-√©conomiques**
- Profils "blue-collar" ‚Üí souscrivent moins
- Profils "management" / "technician" ‚Üí souscrivent plus

**2. Comportement bancaire**
- `duration` √©lev√©e ‚Üí forte corr√©lation avec "yes"

**3. Variables macro-√©conomiques**
- Taux `euribor3m` faibles ‚Üí plus de souscriptions

**4. Multicorr√©lation**
- Colonnes corr√©l√©es : `euribor3m`, `cons.price.idx`, `nr.employed`
- ‚úÖ Pas de probl√®me pour Random Forest
- ‚ö†Ô∏è Probl√©matique pour R√©gression Logistique

---

## 5Ô∏è‚É£ M√©thodologie : Split Train/Test

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

### Pourquoi ces param√®tres ?

| Param√®tre | Valeur | Raison |
|-----------|--------|--------|
| `test_size` | 0.2 (20%) | √âquilibre train/test optimal |
| `random_state` | 42 | Reproductibilit√© des r√©sultats |

### ‚úÖ Pr√©vention du Data Leakage

Le **Pipeline Scikit-Learn** garantit que :
- L'imputation et l'encodage sont ajust√©s uniquement sur le **train**
- Puis appliqu√©s au **test**

**‚û°Ô∏è Bonne pratique industrielle**

---

## 6Ô∏è‚É£ FOCUS : Pourquoi Random Forest excelle ici ?

### Avantages pour ce Cas d'Usage

‚úÖ G√®re variables num√©riques + cat√©gorielles  
‚úÖ Capture les interactions non lin√©aires  
‚úÖ R√©siste aux outliers  
‚úÖ Supporte les corr√©lations fortes  
‚úÖ √âvite l'overfitting (bagging)  

### üî• Principe : Une Arm√©e d'Arbres

**Chaque arbre :**
1. Voit un sous-√©chantillon diff√©rent (bootstrapping)
2. Apprend des r√®gles diff√©rentes
3. Se concentre sur des colonnes al√©atoires

**‚û°Ô∏è Diversit√© = Robustesse**

### Exemple Concret dans Bank Marketing

```
Arbre 1 : classe selon [age, job]
Arbre 2 : classe selon [duration, poutcome]
Arbre 3 : classe selon [macro-√©conomie]
```

Chacun se trompe parfois‚Ä¶  
**Mais le vote collectif annule les erreurs individuelles !**

---

## 7Ô∏è‚É£ √âvaluation : Les M√©triques qui Comptent

### üßÆ Matrice de Confusion

Pour une banque, les erreurs ont un co√ªt :

| Erreur | Impact |
|--------|--------|
| **Faux Positifs (FP)** | Appels inutiles ‚Üí co√ªt op√©rationnel |
| **Faux N√©gatifs (FN)** | Clients perdus ‚Üí **manque √† gagner** |

### üìå M√©triques Marketing Critiques

**1. Precision (classe "yes")**
- Mesure la qualit√© du ciblage
- Si faible ‚Üí gaspillage d'appels

**2. Recall (classe "yes")** ‚≠ê **PRIORIT√â**
- *"Parmi les clients r√©ellement int√©ress√©s, combien capte-t-on ?"*
- **Objectif** : Maximiser le Recall, m√™me si Precision baisse

**3. F1-Score**
- Compromis harmonique entre Precision & Recall

---

## üéØ Conclusion : Intelligence Marketing Bas√©e IA

### Ce Projet D√©montre Que :

1. **Le ML n'est pas qu'une pr√©diction** ‚Üí c'est une strat√©gie business compl√®te
2. **L'analyse m√©tier dicte les m√©triques** ‚Üí ici : Recall sur "yes"
3. **Le preprocessing structur√©** ‚Üí r√©duit les erreurs humaines
4. **Random Forest** ‚Üí excellent pour un premier prototype robuste

### Impact Business

| Avant ML | Apr√®s ML |
|----------|----------|
| Appels al√©atoires | Ciblage intelligent |
| Taux conversion faible | Taux optimis√© |
| Co√ªt √©lev√© | Budget optimis√© |
| √âquipes fatigu√©es | Productivit√© am√©lior√©e |

**üéØ Ce mod√®le aide la banque √† appeler moins... mais mieux !**

---

## üìö Pour Aller Plus Loin

### Am√©liorations Possibles

1. **Gestion du d√©s√©quilibre**
   - SMOTE (sur-√©chantillonnage)
   - Ajustement des poids de classe
   - Seuil de d√©cision personnalis√©

2. **Feature Engineering**
   - Retirer `duration` pour la production
   - Cr√©er des interactions (ex: age √ó job)
   - Agr√©gations macro-√©conomiques

3. **Autres Mod√®les**
   - XGBoost (performances souvent sup√©rieures)
   - LightGBM (plus rapide)
   - R√©gression Logistique (baseline interpr√©table)

4. **Optimisation Hyperparam√®tres**
   - GridSearchCV / RandomizedSearchCV
   - Bayesian Optimization

### D√©ploiement

```python
# Sauvegarder le mod√®le
import joblib
joblib.dump(model, 'bank_marketing_model.pkl')

# Charger et utiliser
model_loaded = joblib.load('bank_marketing_model.pkl')
predictions = model_loaded.predict(new_customers)
```

---

